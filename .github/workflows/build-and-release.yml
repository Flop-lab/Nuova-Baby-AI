name: Build and Release DMG

on:
  push:
    tags:
      - 'v*'

jobs:
  build-dmg:
    strategy:
      fail-fast: false
      matrix:
        include:
          - platform: macos-latest
            target: aarch64-apple-darwin
            arch: ARM64
          - platform: macos-13
            target: x86_64-apple-darwin
            arch: Intel

    runs-on: ${{ matrix.platform }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.91.1
          targets: ${{ matrix.target }}

      - name: Install Tauri CLI
        run: cargo install tauri-cli --version 2.9.4 --locked

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pyinstaller

      - name: Build Python backend with PyInstaller
        run: |
          pyinstaller --onefile \
            --name babyai-backend \
            --hidden-import uvicorn \
            --hidden-import uvicorn.logging \
            --hidden-import uvicorn.loops \
            --hidden-import uvicorn.loops.auto \
            --hidden-import uvicorn.protocols \
            --hidden-import uvicorn.protocols.http \
            --hidden-import uvicorn.protocols.http.auto \
            --hidden-import uvicorn.protocols.websockets \
            --hidden-import uvicorn.protocols.websockets.auto \
            --hidden-import uvicorn.lifespan \
            --hidden-import uvicorn.lifespan.on \
            --collect-all fastapi \
            --collect-all pydantic \
            --collect-all starlette \
            backend_entry.py
          
          # Verify the backend was built
          ls -lh dist/babyai-backend
          
          # Test the backend binary
          ./dist/babyai-backend --help || echo "Backend binary created successfully"

      - name: Download and verify Ollama binary
        run: |
          mkdir -p src-tauri/binaries
          cd src-tauri/binaries
          
          OLLAMA_VERSION="0.12.10"
          OLLAMA_SHA256="cd05049d4202091629403a33a5f345a584fcd86cd82e66c1fbe9c23c5f39f175"
          
          echo "ðŸ“¦ Downloading Ollama Server v${OLLAMA_VERSION}..."
          curl -L -o ollama-darwin.tgz \
            "https://github.com/ollama/ollama/releases/download/v${OLLAMA_VERSION}/ollama-darwin.tgz"
          
          tar -xzf ollama-darwin.tgz ollama
          rm ollama-darwin.tgz
          
          echo "${OLLAMA_SHA256}  ollama" | shasum -a 256 -c -
          
          # Rename binary to include target architecture for Tauri
          mv ollama "ollama-${{ matrix.target }}"
          chmod 755 "ollama-${{ matrix.target }}"
          echo "âœ… Ollama binary ready as ollama-${{ matrix.target }} ($(du -h "ollama-${{ matrix.target }}" | cut -f1))"

      - name: Install UI dependencies
        working-directory: ui
        run: npm ci

      - name: Build UI
        working-directory: ui
        run: npm run build

      - name: Build Tauri DMG for ${{ matrix.arch }}
        run: |
          cargo tauri build --target ${{ matrix.target }}

      - name: Upload DMG artifact
        uses: actions/upload-artifact@v4
        with:
          name: baby-ai-dmg-${{ matrix.arch }}
          path: src-tauri/target/${{ matrix.target }}/release/bundle/dmg/*.dmg
          if-no-files-found: error
